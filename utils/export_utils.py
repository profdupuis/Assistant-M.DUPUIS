"""
Fonctions d'export LaTeX et texte brut pour les conversations assistant-√©l√®ve.

Ce module fournit :
- la conversion des messages assistant/√©l√®ve (cconv) en format LaTeX ou TXT
- le nettoyage des caract√®res probl√©matiques pour LaTeX
- la normalisation des titres d'exercice
- la d√©coupe intelligente des messages en sections par exercice
- la compilation automatique d'un fichier PDF via pdflatex
- un fallback vers un fichier texte brut si la g√©n√©ration LaTeX √©choue

Les formats g√©r√©s :
- `.pdf` (via LaTeX) avec math, code (`lstlisting`), titres, r√¥les
- `.txt` structur√© par exercice avec indentation

D√©pendances :
- Flask (session, logger)
- SQLAlchemy (text)
- pdflatex (doit √™tre install√© pour produire les fichiers PDF)

Ce module est destin√© √† √™tre utilis√© dans un contexte Flask avec une session active.
"""


import os
import re
import tempfile
import subprocess
from io import StringIO
from textwrap import indent
from collections import defaultdict

from flask import session, Response, send_file, current_app as app
from sqlalchemy import text


def normalize_quotes(text):
    """
    Remplace les guillemets typographiques et caract√®res similaires par leurs √©quivalents simples.

    - Remplace les apostrophes et guillemets typographiques (‚Äò‚Äô, ‚Äú‚Äù) par ' et "
    - Corrige les accents mal encod√©s et backticks isol√©s
    - √âvite les erreurs dans LaTeX ou dans le traitement de texte brut

    Retourne une version normalis√©e du texte.
    """
    return (
        text.replace("‚Äò", "'")
            .replace("‚Äô", "'")
            .replace("‚Äú", '"')
            .replace("‚Äù", '"')
            .replace("¬¥", "'")     # accent aigu mal converti
            .replace("`", "'")     # backtick isol√© (souvent probl√©matique en LaTeX)
            .replace("‚Äõ", "'")     # single high-reversed-9 quote
            .replace("‚Ä≥", '"')     # double prime
            .replace("‚Ä∂", '"')     # double high-reversed-9 quote
    )


def normaliser_titre_exo(raw: str) -> str:
    """
    Convertit un titre d'exercice en forme homog√®ne : Exercice X [niveau Y]
    """
    if not raw:
        return "Introduction"
    raw = raw.strip()

    # Majuscules normalis√©es ‚Üí minuscules, capitalise ensuite
    raw = raw.lower()

    # Uniformisation : EXERCICE X (niveau Y) ‚Üí Exercice X [niveau Y]
    raw = raw.replace("exercice", "Exercice")
    raw = raw.replace("(", "[")
    raw = raw.replace(")", "]")

    return raw


def clean_code_block_for_latex(code):
    """
    Nettoie un bloc de code destin√© √† un environnement LaTeX lstlisting.

    - Remplace certaines commandes LaTeX techniques (\cf, \tg, \ln) par leur √©quivalent texte
    - Supprime les caract√®res non-ASCII (emoji, symboles invisibles)
    - Laisse le reste du code intact

    Retourne un code nettoy√©, compatible avec \begin{lstlisting}...\end{lstlisting}.
    """
    code = code.replace(r"\cf", "cf")
    code = code.replace(r"\tg", "tan")
    code = code.replace(r"\ln", "log")
    code = re.sub(r'[^\x00-\x7F]+', '', code)
    return code

def sanitize_tex(text):
    """Nettoie une cha√Æne pour LaTeX en √©chappant les caract√®res sp√©ciaux et en supprimant les emojis."""
    if not text:
        return ""
    # Remplacer les caract√®res sp√©ciaux LaTeX
    replacements = {
        '&': r'\&',
        '%': r'\%',
        '$': r'\$',
        '#': r'\#',
        '_': r'\_',
        '{': r'\{',
        '}': r'\}',
        '~': r'\textasciitilde{}',
        '^': r'\textasciicircum{}',
        '\\': r'\textbackslash{}',
    }
    for old, new in replacements.items():
        text = text.replace(old, new)

    # Supprimer TOUS les caract√®res Unicode non-ASCII (emoji, symboles sp√©ciaux)
    text = re.sub(r'[^\x00-\x7F]+', '', text)

    return text


def sanitize_tex_preserving_math(text: str) -> str:
    """
    Pr√©pare un texte pour une insertion s√ªre dans un document LaTeX.

    Cette fonction :
    - remplace les guillemets typographiques et normalise les apostrophes
    - supprime les caract√®res Unicode non compatibles (emojis, etc.)
    - prot√®ge les blocs \texttt{...} pour √©viter qu'ils ne soient √©chapp√©s
    - √©chappe tous les caract√®res sp√©ciaux LaTeX en dehors des environnements math√©matiques
    - applique le rendu \textbf{...} pour les doubles ast√©risques (Markdown ‚Üí LaTeX)
    - conserve intactes les formules math√©matiques dans \(...\), \[...\] ou $$...$$

    Retourne le texte format√©, pr√™t √† √™tre ins√©r√© dans un document LaTeX.
    """
    text = normalize_quotes(text)

    # üî¥ Supprime les emojis et autres caract√®res unicode probl√©matiques
    text = re.sub(r'[^\x00-\xFF]', '', text)

    math_pattern = re.compile(r'(\\\(.+?\\\)|\\\[.+?\\\]|\$\$.+?\$\$)', re.DOTALL)
    parts = math_pattern.split(text)

    protected_texttt = []

    def protect_texttt(match):
        protected_texttt.append(match.group(0))
        return f"__TEXTTT_{len(protected_texttt)}__"

    text = re.sub(r'\\texttt\{[^}]*\}', protect_texttt, text)

    sanitized_parts = []
    for i, part in enumerate(parts):
        if i % 2 == 1:
            sanitized_parts.append(part)
        else:
            replacements = {
                '&': r'\&',
                '%': r'\%',
                '$': r'\$',
                '#': r'\#',
                '_': r'\_',
                '{': r'\{',
                '}': r'\}',
                '~': r'\textasciitilde{}',
                '^': r'\textasciicircum{}',#'\\': r'\textbackslash{}',
            }
            for old, new in replacements.items():
                part = part.replace(old, new)

            part = re.sub(r'\*\*(.+?)\*\*', r'\\textbf{\1}', part)
            part = re.sub(r'\n{2,}', '\n\n', part)
            sanitized_parts.append(part)

    final_text = ''.join(sanitized_parts)

    # Restaurer les blocs \texttt{...} prot√©g√©s
    for i, original in enumerate(protected_texttt):
        final_text = final_text.replace(f"__TEXTTT_{i}__", original)

    return final_text


def filter_latex_macros(tex):
    """
    Filtre certaines macros LaTeX math√©matiques mal interpr√©t√©es et les remplace par leur √©quivalent texte.

    - Remplace \cf par cf
    - Remplace \tg par tan
    - Remplace \ln par log
    - Ne remplace que les macros isol√©es (\macro suivies d‚Äôun espace, point, etc.)

    Utile pour corriger automatiquement les notations GPT non compatibles ou non souhait√©es dans un contexte PDF.
    """
    tex = re.sub(r'\\cf\b', r'cf', tex)
    tex = re.sub(r'\\tg\b', r'tan', tex)
    tex = re.sub(r'\\ln\b', r'log', tex)
    return tex


def format_content_latex(content):
    """
    Transforme un contenu texte enrichi (Markdown simplifi√©) en LaTeX.

    - D√©tecte et extrait les blocs de code Markdown (```lang\ncode```), rendus en \\begin{lstlisting}...\end{lstlisting}
    - Traite le texte hors code avec sanitize_tex_preserving_math() pour √©chapper les caract√®res LaTeX
    - Corrige les blocs math√©matiques \\[...\\] et $$...$$ mal form√©s
    - Retourne un contenu LaTeX pr√™t √† √™tre inject√© dans le document (section, message IA, etc.)

    Cette fonction suppose que `content` contient un format de type Markdown minimal, tel qu‚Äôutilis√© par l‚ÄôIA dans les r√©ponses structur√©es.
    """
    parts = re.split(r"```([a-z]*)\n([\s\S]*?)```", content)
    latex = ""

    for i in range(0, len(parts), 3):
        texte = parts[i].strip()
        if texte:
            # √âlimine tous les sauts de ligne probl√©matiques dans les \[...\]
            texte = re.sub(r'\\\[(.+?)\\\]', 
                           lambda m: "\\[" + " ".join(m.group(1).split()) + "\\]", 
                           texte, 
                           flags=re.DOTALL)
            
            # M√™me nettoyage pour $$...$$
            texte = re.sub(r'\$\$(.+?)\$\$', 
                           lambda m: "\\[" + " ".join(m.group(1).split()) + "\\]", 
                           texte, 
                           flags=re.DOTALL)
            latex += sanitize_tex_preserving_math(texte).replace("\n", "\n\n") + "\n\n"

        if i + 2 < len(parts):
            lang = parts[i+1].strip()
            code = parts[i+2].strip()

            code = clean_code_block_for_latex(code)

            latex += r"\begin{lstlisting}" + "\n"
            latex += code + "\n"
            latex += r"\end{lstlisting}" + "\n\n"

    return latex



def retirer_prompt_cache(content: str, role: str) -> str:
    """
    Supprime les parties de message utilisateur qui commencent √† ‚ö†Ô∏è (prompt cach√©).
    Utilis√© pour les exports PDF/TXT.
    """
    if role in ("user", "√©l√®ve"):
        return content.split("‚ö†Ô∏è")[0].strip()
    return content.strip()

def tri_exercice_key(titre: str):
    """
    Extrait un tuple de tri √† partir d'un titre de type :
    'Exercice 1', 'Exercice 1bis', 'Exercice 2', etc.
    
    Renvoie (num√©ro, suffixe) ‚Üí ex : (1, 'bis') ou (2, '').
    Si √©chec : renvoie un tuple tr√®s haut pour aller √† la fin.
    """
    match = re.search(r'exercice\s+(\d+)([a-z]*)', titre.lower())
    if match:
        num = int(match.group(1))
        suffixe = match.group(2)
        return (num, suffixe)
    return (9999, titre.lower())  # fallback


def decouper_conversation_par_exercice(history):
    """
    D√©coupe les messages en sections :
    - Introduction (meta.subtype = intro)
    - Exercices (par "exo" ou üß©)
    - Bilan final (meta.subtype = feedback)
    """

    sections = defaultdict(list)
    current_exo = None

    for msg in history:
        role = msg.get("role", "")
        content = retirer_prompt_cache(msg.get("content", ""), role)
        subtype = msg.get("subtype", None)
        
        if not content:
            continue
        
        # --- Gestion des messages META avec subtype ---
        if role == "meta":
            if subtype == "intro":
                sections["Introduction"].append((role, subtype, content))
            elif subtype == "feedback":
                sections["üìù Bilan final"].append((role, subtype, content))
            else:
                sections["üìù Bilan final"].append((role, subtype, content))  # Par d√©faut
            continue
        
        # --- Navigation vers un exo (depuis bouton ou commande texte) ---
        if role == "exo":
            current_exo = content.split(":")[0].strip()
            continue  # l'√©nonc√© sera ajout√© dynamiquement via MAP_JSON

        # --- D√©tection d‚Äôun exo g√©n√©r√© dynamiquement par l‚ÄôIA (üß©) ---
        if role == "assistant":
            lines = content.splitlines()
            for line in lines:
                if line.strip().startswith("üß©"):
                    titre = line.strip("üß© ").split(":")[0].strip()
                    current_exo = titre
                    if current_exo not in sections:
                        sections[current_exo] = []
                    break
        if current_exo not in sections:
            sections[current_exo] = []

        sections[current_exo].append((role, subtype, content))

    # üü¢ Tri explicite des sections : intro ‚Üí exos (tri√©s) ‚Üí bilan
    ordered_sections = {}

    # Intro d'abord
    if "Introduction" in sections:
        ordered_sections["Introduction"] = sections.pop("Introduction")

    # Exercices par ordre alphab√©tique (ex : Exercice 1, Exercice 2, Exercice 2bis, etc.)
    for k in sorted(sections.keys(), key=tri_exercice_key):  # version 1 simple
        if not k.startswith("üìù"):
            ordered_sections[k] = sections[k]

    # Feedback √† la fin
    if "üìù Bilan final" in sections:
        ordered_sections["üìù Bilan final"] = sections.pop("üìù Bilan final")

    return ordered_sections



def build_conversation_txt(engine):
    """
    Construit une version texte brute de la conversation, organis√©e par exercice.
    """


    history = session.get("cconv", [])
    if not history:
        app.logger.warning("TXT : aucun historique dans cconv.")
        return ""

    # R√©cup√©ration des infos de contexte
    matiere = session.get("active_matiere", "Inconnue").capitalize()
    scenario_id = session.get("active_scenario_id")
    scenario_name = "Sc√©nario en cours"

    with engine.connect() as cn:
        scenario_name = cn.scalar(text("""
            SELECT name FROM scenarios WHERE id = :sid
        """), {"sid": scenario_id}) or scenario_name
        
        
    # creation des sections
    sections = decouper_conversation_par_exercice(history)

    # G√©n√©ration du contenu brut
    output = StringIO()
    output.write(f"üß† Conversation p√©dagogique\n")
    output.write(f"Mati√®re : {matiere}\n")
    output.write(f"Fiche : {scenario_name}\n\n")

    for section, messages in sections.items():
        titre_section = section
        if section == "üìù Bilan final":
            titre_section = "Bilan final"

        output.write(f"========== {titre_section or 'Introduction'} ==========\n\n")

        # Injection automatique de l'√©nonc√© si section = "Exercice X"
        ref = extract_ref_from_section_title(section)
        if ref and ref in session.get("MAP_JSON", {}):
            enonce = session["MAP_JSON"][ref].strip()
            enonce = retirer_premiere_ligne_si_titre(enonce)
            output.write(indent(enonce, "    "))
            output.write("\n\n")
        for role, subtype, content in messages:
            if role == "meta":
                label = {
                    "intro": "Note d‚Äôintroduction",
                    "feedback": "Bilan final"
                }.get(subtype, "Note syst√®me")
            else:
                label = {
                    "user": "√âl√®ve",
                    "assistant": "Assistant IA"
                }.get(role, role.capitalize())
            # üîç Supprime le titre redondant dans les r√©ponses assistant IA
            if role == "assistant":
                lines = content.strip().splitlines()
                if lines and lines[0].strip().lower().startswith("üß© exercice"):
                    content = "\n".join(lines[1:]).strip()
            output.write(f"--- {label} ---\n")
            output.write(indent(content.strip(), "    "))
            output.write("\n\n")

    return output.getvalue()

def extract_ref_from_section_title(title: str) -> str | None:
    """
    √Ä partir d'un titre de section du type 'EXERCICE 2bis [niveau 1]',
    extrait la r√©f√©rence 'exo_2bis'.
    """
    match = re.search(r"exercice\s+([a-z0-9]+)", title, re.IGNORECASE)
    return f"exo_{match.group(1).lower()}" if match else None

def retirer_premiere_ligne_si_titre(enonce: str) -> str:
    """
    Supprime la premi√®re ligne de l'√©nonc√© si elle commence par 'EXERCICE',
    afin d'√©viter la redondance dans le PDF (d√©j√† dans \section).
    """
    lines = enonce.strip().splitlines()
    if lines:
        first = lines[0].strip().lower()
        if first.startswith("exercice") or first.startswith("üß© exercice"):
            return "\n".join(lines[1:]).strip()
    return enonce.strip()




def build_conversation_pdf(engine):
    """
    G√©n√®re un PDF de la conversation p√©dagogique, organis√© par exercice.
    """
    

    history = session.get("cconv", [])
    if not history:
        app.logger.warning("PDF : aucun historique dans cconv.")
        return None

    # Informations de contexte
    matiere = session.get("active_matiere", "").capitalize()
    scenario_id = session.get("active_scenario_id")
    scenario_name = "Sc√©nario en cours"

    # R√©cup√©ration du nom de la fiche
    with engine.connect() as cn:
        scenario_name = cn.scalar(text("""
            SELECT name FROM scenarios WHERE id = :sid
        """), {"sid": scenario_id}) or scenario_name

    # Tri des messages par bloc d'exercice
    sections = decouper_conversation_par_exercice(history)


    # Construction du LaTeX
    tex = r"""
    \documentclass{article}
    \usepackage[utf8]{inputenc}
    \usepackage[T1]{fontenc}
    \usepackage[french]{babel}
    \usepackage{geometry}
    \usepackage{xcolor}
    \usepackage{listings}
    \usepackage{fancyvrb}
    \usepackage{amsmath}
    \usepackage{amssymb}
    \geometry{a4paper, margin=1in}
    \definecolor{lightgray}{gray}{0.95}
    \lstset{
        backgroundcolor=\color{lightgray},
        basicstyle=\ttfamily\small,
        breaklines=true,
        frame=single
    }
    \title{Conversation p√©dagogique}
    \date{}
    \begin{document}
    """  # C'est une raw-string, donc OK pour le pr√©ambule

    tex += f"""
    \\maketitle

    \\textbf{{Mati√®re}} : {sanitize_tex(matiere)}\\\\
    \\textbf{{Nom de la fiche}} : {sanitize_tex(scenario_name)}

    \\bigskip
    """

    meta_seen = False
    
    for section, messages in sections.items():
        titre = sanitize_tex_preserving_math(normaliser_titre_exo(section))
        tex += f"\\section*{{{titre}}}\n\n"

        # Injection automatique de l'√©nonc√© si section = "Exercice X"
        ref = extract_ref_from_section_title(section)
        if ref and ref in session.get("MAP_JSON", {}): # si cest un exo de la fiche
            enonce = session["MAP_JSON"][ref].strip()
            enonce = retirer_premiere_ligne_si_titre(enonce)
            tex += format_content_latex(enonce) + "\n\n"


        for role, subtype, content in messages:
            if role == "meta":
                role_title = {
                    "intro": "Note d‚Äôintroduction",
                    "feedback": "Bilan final"
                }.get(subtype, "Note syst√®me")
            else:
                role_title = {
                    "user": "√âl√®ve",
                    "assistant": "Assistant IA"
                }.get(role, role.capitalize())

            # üîç Supprime le titre d‚Äôexercice dans la r√©ponse assistant s‚Äôil est redondant
            if role == "assistant":
                lines = content.strip().splitlines()
                if lines and lines[0].strip().lower().startswith("üß© exercice"):
                    content = "\n".join(lines[1:]).strip()
            
            
            tex += f"\\subsection*{{{role_title}}}\n"
            
            tex += format_content_latex(content) + "\n\n"

    tex += r"\end{document}"



    # Compilation LaTeX
    tmpdirname = tempfile.mkdtemp()
    try:
        tex_path = os.path.join(tmpdirname, "conversation.tex")
        with open(tex_path, "w", encoding="utf-8") as f:
            safe_tex = normalize_quotes(tex)
            f.write(safe_tex)

        result = subprocess.run(
            ["pdflatex", "-interaction=nonstopmode", "conversation.tex"],
            cwd=tmpdirname,
            check=True,
            capture_output=True,
            text=True,
            encoding="utf-8",
            errors="replace"
        )

        app.logger.info(f"PDF g√©n√©r√© avec succ√®s : {result.stdout}")

        pdf_path = os.path.join(tmpdirname, "conversation.pdf")
        return pdf_path

    except subprocess.CalledProcessError as e:
        app.logger.error("‚ùå Erreur compilation pdflatex :")
        app.logger.error(e.stdout)
        app.logger.error(e.stderr)
        return None
    except Exception as e:
        app.logger.error(f"Erreur inattendue : {e}")
        return None


    finally:
        try:
            clean_temp_folder()
        except Exception as e:
            app.logger.warning(f"Erreur nettoyage : {e}")


